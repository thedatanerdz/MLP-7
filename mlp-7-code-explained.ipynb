{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42cf6166",
   "metadata": {
    "papermill": {
     "duration": 0.005613,
     "end_time": "2023-05-26T23:44:00.458691",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.453078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stock Sentiment Analysis using News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fab0f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:00.470325Z",
     "iopub.status.busy": "2023-05-26T23:44:00.469946Z",
     "iopub.status.idle": "2023-05-26T23:44:00.478822Z",
     "shell.execute_reply": "2023-05-26T23:44:00.478027Z"
    },
    "papermill": {
     "duration": 0.016804,
     "end_time": "2023-05-26T23:44:00.480457",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.463653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5483b8",
   "metadata": {
    "papermill": {
     "duration": 0.004728,
     "end_time": "2023-05-26T23:44:00.490400",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.485672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "pandas is a powerful open-source data manipulation and analysis library in Python. It provides data structures and functions to efficiently work with structured data, such as tabular data, time series, and more.\n",
    "\n",
    "By importing pandas as pd, you can refer to its functions and objects using the pd prefix. This is a common convention used by developers to make code more concise and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bae462f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:00.501609Z",
     "iopub.status.busy": "2023-05-26T23:44:00.501313Z",
     "iopub.status.idle": "2023-05-26T23:44:00.674175Z",
     "shell.execute_reply": "2023-05-26T23:44:00.673332Z"
    },
    "papermill": {
     "duration": 0.180875,
     "end_time": "2023-05-26T23:44:00.676177",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.495302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/kaggle/input/stock-sentiment-analysis-data/stock_senti_analysis.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2901670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:00.689061Z",
     "iopub.status.busy": "2023-05-26T23:44:00.688772Z",
     "iopub.status.idle": "2023-05-26T23:44:00.726981Z",
     "shell.execute_reply": "2023-05-26T23:44:00.726145Z"
    },
    "papermill": {
     "duration": 0.046138,
     "end_time": "2023-05-26T23:44:00.728969",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.682831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United's rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne (Australia)</td>\n",
       "      <td>Necaxa (Mexico)</td>\n",
       "      <td>Real Madrid (Spain)</td>\n",
       "      <td>Raja Casablanca (Morocco)</td>\n",
       "      <td>Corinthians (Brazil)</td>\n",
       "      <td>Tony's pet project</td>\n",
       "      <td>Al Nassr (Saudi Arabia)</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress</td>\n",
       "      <td>Thatcher facing ban</td>\n",
       "      <td>McIlroy calls for Irish fighting spirit</td>\n",
       "      <td>Leicester bin stadium blueprint</td>\n",
       "      <td>United braced for Mexican wave</td>\n",
       "      <td>Auntie back in fashion, even if the dress look...</td>\n",
       "      <td>Shoaib appeal goes to the top</td>\n",
       "      <td>Hussain hurt by 'shambles' but lays blame on e...</td>\n",
       "      <td>...</td>\n",
       "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
       "      <td>BBC worst hit as digital TV begins to bite</td>\n",
       "      <td>How much can you pay for...</td>\n",
       "      <td>Christmas glitches</td>\n",
       "      <td>Upending a table, Chopping a line and Scoring ...</td>\n",
       "      <td>Scientific evidence 'unreliable', defence claims</td>\n",
       "      <td>Fusco wins judicial review in extradition case</td>\n",
       "      <td>Rebels thwart Russian advance</td>\n",
       "      <td>Blair orders shake-up of failing NHS</td>\n",
       "      <td>Lessons of law's hard heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks</td>\n",
       "      <td>Beckham off but United survive</td>\n",
       "      <td>Breast cancer screening</td>\n",
       "      <td>Alan Parker</td>\n",
       "      <td>Guardian readers: are you all whingers?</td>\n",
       "      <td>Hollywood Beyond</td>\n",
       "      <td>Ashes and diamonds</td>\n",
       "      <td>Whingers - a formidable minority</td>\n",
       "      <td>...</td>\n",
       "      <td>Most everywhere:  UDIs</td>\n",
       "      <td>Most wanted:  Chloe lunettes</td>\n",
       "      <td>Return of the cane 'completely off the agenda'</td>\n",
       "      <td>From Sleepy Hollow to Greeneland</td>\n",
       "      <td>Blunkett outlines vision for over 11s</td>\n",
       "      <td>Embattled Dobson attacks 'play now, pay later'...</td>\n",
       "      <td>Doom and the Dome</td>\n",
       "      <td>What is the north-south divide?</td>\n",
       "      <td>Aitken released from jail</td>\n",
       "      <td>Gone aloft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1  2000-01-04      0                                          Scorecard   \n",
       "2  2000-01-05      0                  Coventry caught on counter by Flo   \n",
       "3  2000-01-06      1                      Pilgrim knows how to progress   \n",
       "4  2000-01-07      1                               Hitches and Horlocks   \n",
       "\n",
       "                                 Top2  \\\n",
       "0                           Scorecard   \n",
       "1                 The best lake scene   \n",
       "2  United's rivals on the road to Rio   \n",
       "3                 Thatcher facing ban   \n",
       "4      Beckham off but United survive   \n",
       "\n",
       "                                            Top3  \\\n",
       "0                Hughes' instant hit buoys Blues   \n",
       "1                  Leader: German sleaze inquiry   \n",
       "2  Thatcher issues defence before trial by video   \n",
       "3        McIlroy calls for Irish fighting spirit   \n",
       "4                        Breast cancer screening   \n",
       "\n",
       "                                            Top4  \\\n",
       "0       Jack gets his skates on at ice-cold Alex   \n",
       "1                                  Cheerio, boyo   \n",
       "2  Police help Smith lay down the law at Everton   \n",
       "3                Leicester bin stadium blueprint   \n",
       "4                                    Alan Parker   \n",
       "\n",
       "                                          Top5  \\\n",
       "0       Chaos as Maracana builds up for United   \n",
       "1                     The main recommendations   \n",
       "2  Tale of Trautmann bears two more retellings   \n",
       "3               United braced for Mexican wave   \n",
       "4      Guardian readers: are you all whingers?   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees?   \n",
       "2                                England on the rack   \n",
       "3  Auntie back in fashion, even if the dress look...   \n",
       "4                                   Hollywood Beyond   \n",
       "\n",
       "                                              Top7  \\\n",
       "0                 Hungry Spurs sense rich pickings   \n",
       "1                           Has Cubie killed fees?   \n",
       "2  Pakistan retaliate with call for video of Walsh   \n",
       "3                    Shoaib appeal goes to the top   \n",
       "4                               Ashes and diamonds   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0                  Gunners so wide of an easy target  ...   \n",
       "1                             Has Cubie killed fees?  ...   \n",
       "2               Cullinan continues his Cape monopoly  ...   \n",
       "3  Hussain hurt by 'shambles' but lays blame on e...  ...   \n",
       "4                   Whingers - a formidable minority  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0           Flintoff injury piles on woe for England   \n",
       "1                               On the critical list   \n",
       "2                        South Melbourne (Australia)   \n",
       "3  Putin admits Yeltsin quit to give him a head s...   \n",
       "4                             Most everywhere:  UDIs   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "2                                    Necaxa (Mexico)   \n",
       "3         BBC worst hit as digital TV begins to bite   \n",
       "4                       Most wanted:  Chloe lunettes   \n",
       "\n",
       "                                            Top18  \\\n",
       "0             Kohl's successor drawn into scandal   \n",
       "1                                     Dear doctor   \n",
       "2                             Real Madrid (Spain)   \n",
       "3                     How much can you pay for...   \n",
       "4  Return of the cane 'completely off the agenda'   \n",
       "\n",
       "                                               Top19  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man's extradition to Nor...   \n",
       "2                          Raja Casablanca (Morocco)   \n",
       "3                                 Christmas glitches   \n",
       "4                   From Sleepy Hollow to Greeneland   \n",
       "\n",
       "                                               Top20  \\\n",
       "0                Sara Denver, nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "2                               Corinthians (Brazil)   \n",
       "3  Upending a table, Chopping a line and Scoring ...   \n",
       "4              Blunkett outlines vision for over 11s   \n",
       "\n",
       "                                               Top21  \\\n",
       "0     Diana's landmine crusade put Tories in a panic   \n",
       "1               PE points the way forward to the ECB   \n",
       "2                                 Tony's pet project   \n",
       "3   Scientific evidence 'unreliable', defence claims   \n",
       "4  Embattled Dobson attacks 'play now, pay later'...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...   \n",
       "1  Campaigners keep up pressure on Nazi war crime...   \n",
       "2                            Al Nassr (Saudi Arabia)   \n",
       "3     Fusco wins judicial review in extradition case   \n",
       "4                                  Doom and the Dome   \n",
       "\n",
       "                             Top23  \\\n",
       "0                 Russian roulette   \n",
       "1                   Jane Ratcliffe   \n",
       "2                Ideal Holmes show   \n",
       "3    Rebels thwart Russian advance   \n",
       "4  What is the north-south divide?   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn't know without the ...   \n",
       "2               Pinochet leaves hospital after tests   \n",
       "3               Blair orders shake-up of failing NHS   \n",
       "4                          Aitken released from jail   \n",
       "\n",
       "                          Top25  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "2                  Useful links  \n",
       "3   Lessons of law's hard heart  \n",
       "4                    Gone aloft  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d67fc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:00.742141Z",
     "iopub.status.busy": "2023-05-26T23:44:00.741868Z",
     "iopub.status.idle": "2023-05-26T23:44:00.751306Z",
     "shell.execute_reply": "2023-05-26T23:44:00.750509Z"
    },
    "papermill": {
     "duration": 0.017985,
     "end_time": "2023-05-26T23:44:00.752969",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.734984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '20150101']\n",
    "test = df[df['Date'] > '20141231']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c10259",
   "metadata": {
    "papermill": {
     "duration": 0.005647,
     "end_time": "2023-05-26T23:44:00.764638",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.758991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Overall, this code is separating the data in the df DataFrame into two subsets based on the dates. The train DataFrame contains the data with dates before '20150101', while the test DataFrame contains the data with dates after '20141231'. This type of separation is commonly done in machine learning or time series analysis to split the data into a training set and a testing (or validation) set for model development and evaluation.\n",
    "spliting testing and training data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878a47a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:00.777050Z",
     "iopub.status.busy": "2023-05-26T23:44:00.776772Z",
     "iopub.status.idle": "2023-05-26T23:44:01.162621Z",
     "shell.execute_reply": "2023-05-26T23:44:01.161811Z"
    },
    "papermill": {
     "duration": 0.394292,
     "end_time": "2023-05-26T23:44:01.164481",
     "exception": false,
     "start_time": "2023-05-26T23:44:00.770189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A  hindrance to operations   extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes  instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>Derby raise a glass to Strupar s debut double</td>\n",
       "      <td>Southgate strikes  Leeds pay the penalty</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl s successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver  nurse turned solicitor</td>\n",
       "      <td>Diana s landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin s resignation caught opposition flat f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader  German sleaze inquiry</td>\n",
       "      <td>Cheerio  boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>Hopkins  furious  at Foster s lack of Hannibal...</td>\n",
       "      <td>Has Cubie killed fees</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man s extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn t know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United s rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>McGrath puts India out of their misery</td>\n",
       "      <td>Blair Witch bandwagon rolls on</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne  Australia</td>\n",
       "      <td>Necaxa  Mexico</td>\n",
       "      <td>Real Madrid  Spain</td>\n",
       "      <td>Raja Casablanca  Morocco</td>\n",
       "      <td>Corinthians  Brazil</td>\n",
       "      <td>Tony s pet project</td>\n",
       "      <td>Al Nassr  Saudi Arabia</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pilgrim knows how to progress</td>\n",
       "      <td>Thatcher facing ban</td>\n",
       "      <td>McIlroy calls for Irish fighting spirit</td>\n",
       "      <td>Leicester bin stadium blueprint</td>\n",
       "      <td>United braced for Mexican wave</td>\n",
       "      <td>Auntie back in fashion  even if the dress look...</td>\n",
       "      <td>Shoaib appeal goes to the top</td>\n",
       "      <td>Hussain hurt by  shambles  but lays blame on e...</td>\n",
       "      <td>England s decade of disasters</td>\n",
       "      <td>Revenge is sweet for jubilant Cronje</td>\n",
       "      <td>...</td>\n",
       "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
       "      <td>BBC worst hit as digital TV begins to bite</td>\n",
       "      <td>How much can you pay for</td>\n",
       "      <td>Christmas glitches</td>\n",
       "      <td>Upending a table  Chopping a line and Scoring ...</td>\n",
       "      <td>Scientific evidence  unreliable   defence claims</td>\n",
       "      <td>Fusco wins judicial review in extradition case</td>\n",
       "      <td>Rebels thwart Russian advance</td>\n",
       "      <td>Blair orders shake up of failing NHS</td>\n",
       "      <td>Lessons of law s hard heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hitches and Horlocks</td>\n",
       "      <td>Beckham off but United survive</td>\n",
       "      <td>Breast cancer screening</td>\n",
       "      <td>Alan Parker</td>\n",
       "      <td>Guardian readers  are you all whingers</td>\n",
       "      <td>Hollywood Beyond</td>\n",
       "      <td>Ashes and diamonds</td>\n",
       "      <td>Whingers   a formidable minority</td>\n",
       "      <td>Alan Parker   part two</td>\n",
       "      <td>Thuggery  Toxins and Ties</td>\n",
       "      <td>...</td>\n",
       "      <td>Most everywhere   UDIs</td>\n",
       "      <td>Most wanted   Chloe lunettes</td>\n",
       "      <td>Return of the cane  completely off the agenda</td>\n",
       "      <td>From Sleepy Hollow to Greeneland</td>\n",
       "      <td>Blunkett outlines vision for over   s</td>\n",
       "      <td>Embattled Dobson attacks  play now  pay later ...</td>\n",
       "      <td>Doom and the Dome</td>\n",
       "      <td>What is the north south divide</td>\n",
       "      <td>Aitken released from jail</td>\n",
       "      <td>Gone aloft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  A  hindrance to operations   extracts from the...   \n",
       "1                                          Scorecard   \n",
       "2                  Coventry caught on counter by Flo   \n",
       "3                      Pilgrim knows how to progress   \n",
       "4                               Hitches and Horlocks   \n",
       "\n",
       "                                    1  \\\n",
       "0                           Scorecard   \n",
       "1                 The best lake scene   \n",
       "2  United s rivals on the road to Rio   \n",
       "3                 Thatcher facing ban   \n",
       "4      Beckham off but United survive   \n",
       "\n",
       "                                               2  \\\n",
       "0                Hughes  instant hit buoys Blues   \n",
       "1                  Leader  German sleaze inquiry   \n",
       "2  Thatcher issues defence before trial by video   \n",
       "3        McIlroy calls for Irish fighting spirit   \n",
       "4                        Breast cancer screening   \n",
       "\n",
       "                                               3  \\\n",
       "0       Jack gets his skates on at ice cold Alex   \n",
       "1                                  Cheerio  boyo   \n",
       "2  Police help Smith lay down the law at Everton   \n",
       "3                Leicester bin stadium blueprint   \n",
       "4                                    Alan Parker   \n",
       "\n",
       "                                             4  \\\n",
       "0       Chaos as Maracana builds up for United   \n",
       "1                     The main recommendations   \n",
       "2  Tale of Trautmann bears two more retellings   \n",
       "3               United braced for Mexican wave   \n",
       "4      Guardian readers  are you all whingers    \n",
       "\n",
       "                                                   5  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees    \n",
       "2                                England on the rack   \n",
       "3  Auntie back in fashion  even if the dress look...   \n",
       "4                                   Hollywood Beyond   \n",
       "\n",
       "                                                 6  \\\n",
       "0                 Hungry Spurs sense rich pickings   \n",
       "1                           Has Cubie killed fees    \n",
       "2  Pakistan retaliate with call for video of Walsh   \n",
       "3                    Shoaib appeal goes to the top   \n",
       "4                               Ashes and diamonds   \n",
       "\n",
       "                                                   7  \\\n",
       "0                  Gunners so wide of an easy target   \n",
       "1                             Has Cubie killed fees    \n",
       "2               Cullinan continues his Cape monopoly   \n",
       "3  Hussain hurt by  shambles  but lays blame on e...   \n",
       "4                   Whingers   a formidable minority   \n",
       "\n",
       "                                                   8  \\\n",
       "0      Derby raise a glass to Strupar s debut double   \n",
       "1  Hopkins  furious  at Foster s lack of Hannibal...   \n",
       "2             McGrath puts India out of their misery   \n",
       "3                      England s decade of disasters   \n",
       "4                             Alan Parker   part two   \n",
       "\n",
       "                                          9  ...  \\\n",
       "0  Southgate strikes  Leeds pay the penalty  ...   \n",
       "1                    Has Cubie killed fees   ...   \n",
       "2            Blair Witch bandwagon rolls on  ...   \n",
       "3      Revenge is sweet for jubilant Cronje  ...   \n",
       "4                 Thuggery  Toxins and Ties  ...   \n",
       "\n",
       "                                                  15  \\\n",
       "0           Flintoff injury piles on woe for England   \n",
       "1                               On the critical list   \n",
       "2                        South Melbourne  Australia    \n",
       "3  Putin admits Yeltsin quit to give him a head s...   \n",
       "4                             Most everywhere   UDIs   \n",
       "\n",
       "                                                  16  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "2                                    Necaxa  Mexico    \n",
       "3         BBC worst hit as digital TV begins to bite   \n",
       "4                       Most wanted   Chloe lunettes   \n",
       "\n",
       "                                               17  \\\n",
       "0             Kohl s successor drawn into scandal   \n",
       "1                                     Dear doctor   \n",
       "2                             Real Madrid  Spain    \n",
       "3                     How much can you pay for      \n",
       "4  Return of the cane  completely off the agenda    \n",
       "\n",
       "                                                  18  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man s extradition to Nor...   \n",
       "2                          Raja Casablanca  Morocco    \n",
       "3                                 Christmas glitches   \n",
       "4                   From Sleepy Hollow to Greeneland   \n",
       "\n",
       "                                                  19  \\\n",
       "0                Sara Denver  nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "2                               Corinthians  Brazil    \n",
       "3  Upending a table  Chopping a line and Scoring ...   \n",
       "4              Blunkett outlines vision for over   s   \n",
       "\n",
       "                                                  20  \\\n",
       "0     Diana s landmine crusade put Tories in a panic   \n",
       "1               PE points the way forward to the ECB   \n",
       "2                                 Tony s pet project   \n",
       "3   Scientific evidence  unreliable   defence claims   \n",
       "4  Embattled Dobson attacks  play now  pay later ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0  Yeltsin s resignation caught opposition flat f...   \n",
       "1  Campaigners keep up pressure on Nazi war crime...   \n",
       "2                            Al Nassr  Saudi Arabia    \n",
       "3     Fusco wins judicial review in extradition case   \n",
       "4                                  Doom and the Dome   \n",
       "\n",
       "                                22  \\\n",
       "0                 Russian roulette   \n",
       "1                   Jane Ratcliffe   \n",
       "2                Ideal Holmes show   \n",
       "3    Rebels thwart Russian advance   \n",
       "4  What is the north south divide    \n",
       "\n",
       "                                                  23  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn t know without the ...   \n",
       "2               Pinochet leaves hospital after tests   \n",
       "3               Blair orders shake up of failing NHS   \n",
       "4                          Aitken released from jail   \n",
       "\n",
       "                             24  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "2                  Useful links  \n",
       "3   Lessons of law s hard heart  \n",
       "4                    Gone aloft  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuations\n",
    "data=train.iloc[:,2:27]\n",
    "data.replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
    "\n",
    "# Renaming column names for ease of access\n",
    "list1= [i for i in range(25)]\n",
    "new_Index=[str(i) for i in list1]\n",
    "data.columns= new_Index\n",
    "data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001da9f",
   "metadata": {
    "papermill": {
     "duration": 0.00582,
     "end_time": "2023-05-26T23:44:01.179277",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.173457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Overall, this code is separating the data in the df DataFrame into two subsets based on the dates. The train DataFrame contains the data with dates before '20150101', while the test DataFrame contains the data with dates after '20141231'. This type of separation is commonly done in machine learning or time series analysis to split the data into a training set and a testing (or validation) set for model development and evaluation.This line uses the replace() method to remove punctuations from the data DataFrame. It replaces any character that is not a letter (denoted by the regular expression pattern [^a-zA-Z]) with a space. The regex=True parameter indicates that the pattern is a regular expression. The inplace=True parameter modifies the data DataFrame in place, without creating a new DataFrame.\n",
    "\n",
    "This step is often performed to clean text data by removing non-alphabetic characters, such as punctuation marks or special characters, to prepare the text for further analysis or natural language processing tasks.These lines rename the column names of the data DataFrame for ease of access. It creates a list list1 containing integers from 0 to 24. Then, it creates a new list new_Index by converting each integer in list1 to a string using a list comprehension.\n",
    "\n",
    "Finally, it assigns the new_Index list as the new column names of the data DataFrame using the columns attribute.\n",
    "\n",
    "This step is optional but can be useful when you want to have more meaningful or descriptive column names instead of the default column names.This line displays the first five rows of the data DataFrame using the head() method. It helps to quickly inspect the resulting DataFrame and verify the changes made.\n",
    "\n",
    "Overall, the code snippet you provided is preprocessing the train DataFrame by selecting specific columns, removing punctuations, and renaming the column names for convenience. The resulting DataFrame is stored in the data variable, and the first five rows are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0af9ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:01.192392Z",
     "iopub.status.busy": "2023-05-26T23:44:01.192071Z",
     "iopub.status.idle": "2023-05-26T23:44:01.251161Z",
     "shell.execute_reply": "2023-05-26T23:44:01.250053Z"
    },
    "papermill": {
     "duration": 0.067719,
     "end_time": "2023-05-26T23:44:01.252851",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.185132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a  hindrance to operations   extracts from the...</td>\n",
       "      <td>scorecard</td>\n",
       "      <td>hughes  instant hit buoys blues</td>\n",
       "      <td>jack gets his skates on at ice cold alex</td>\n",
       "      <td>chaos as maracana builds up for united</td>\n",
       "      <td>depleted leicester prevail as elliott spoils e...</td>\n",
       "      <td>hungry spurs sense rich pickings</td>\n",
       "      <td>gunners so wide of an easy target</td>\n",
       "      <td>derby raise a glass to strupar s debut double</td>\n",
       "      <td>southgate strikes  leeds pay the penalty</td>\n",
       "      <td>...</td>\n",
       "      <td>flintoff injury piles on woe for england</td>\n",
       "      <td>hunters threaten jospin with new battle of the...</td>\n",
       "      <td>kohl s successor drawn into scandal</td>\n",
       "      <td>the difference between men and women</td>\n",
       "      <td>sara denver  nurse turned solicitor</td>\n",
       "      <td>diana s landmine crusade put tories in a panic</td>\n",
       "      <td>yeltsin s resignation caught opposition flat f...</td>\n",
       "      <td>russian roulette</td>\n",
       "      <td>sold out</td>\n",
       "      <td>recovering a title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1  \\\n",
       "0  a  hindrance to operations   extracts from the...  scorecard   \n",
       "\n",
       "                                 2                                         3  \\\n",
       "0  hughes  instant hit buoys blues  jack gets his skates on at ice cold alex   \n",
       "\n",
       "                                        4  \\\n",
       "0  chaos as maracana builds up for united   \n",
       "\n",
       "                                                   5  \\\n",
       "0  depleted leicester prevail as elliott spoils e...   \n",
       "\n",
       "                                  6                                  7  \\\n",
       "0  hungry spurs sense rich pickings  gunners so wide of an easy target   \n",
       "\n",
       "                                               8  \\\n",
       "0  derby raise a glass to strupar s debut double   \n",
       "\n",
       "                                          9  ...  \\\n",
       "0  southgate strikes  leeds pay the penalty  ...   \n",
       "\n",
       "                                         15  \\\n",
       "0  flintoff injury piles on woe for england   \n",
       "\n",
       "                                                  16  \\\n",
       "0  hunters threaten jospin with new battle of the...   \n",
       "\n",
       "                                    17                                    18  \\\n",
       "0  kohl s successor drawn into scandal  the difference between men and women   \n",
       "\n",
       "                                    19  \\\n",
       "0  sara denver  nurse turned solicitor   \n",
       "\n",
       "                                               20  \\\n",
       "0  diana s landmine crusade put tories in a panic   \n",
       "\n",
       "                                                  21                22  \\\n",
       "0  yeltsin s resignation caught opposition flat f...  russian roulette   \n",
       "\n",
       "         23                  24  \n",
       "0  sold out  recovering a title  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertng headlines to lower case\n",
    "for index in new_Index:\n",
    "    data[index]=data[index].str.lower()\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e954a6",
   "metadata": {
    "papermill": {
     "duration": 0.00582,
     "end_time": "2023-05-26T23:44:01.265055",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.259235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code  converts the headlines in the data DataFrame to lowercase. This loop iterates over each column index in the new_Index list, which represents the column names of the data DataFrame. For each column, it uses the .str.lower() method to convert the values in that column to lowercase.\n",
    "\n",
    "The .str accessor provides a set of string methods that can be applied to each element of a column. In this case, .lower() is used to convert the strings to lowercase.\n",
    "\n",
    "The loop iterates over all the columns, and the corresponding columns are modified in-place with the lowercase values.data.head(1)\n",
    "This line displays the first row of the modified data DataFrame after converting the headlines to lowercase.\n",
    "\n",
    "By converting the headlines to lowercase, you ensure that the text is normalized and consistent, which can be helpful for tasks like text matching, analysis, or natural language processing that are case-insensitive.\n",
    "\n",
    "Note that the data DataFrame has undergone several preprocessing steps as shown in the previous code snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "618704de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:01.278679Z",
     "iopub.status.busy": "2023-05-26T23:44:01.278358Z",
     "iopub.status.idle": "2023-05-26T23:44:01.285242Z",
     "shell.execute_reply": "2023-05-26T23:44:01.284417Z"
    },
    "papermill": {
     "duration": 0.015964,
     "end_time": "2023-05-26T23:44:01.287095",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.271131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scorecard the best lake scene leader  german sleaze inquiry cheerio  boyo the main recommendations has cubie killed fees  has cubie killed fees  has cubie killed fees  hopkins  furious  at foster s lack of hannibal appetite has cubie killed fees  a tale of two tails i say what i like and i like what i say elbows  eyes and nipples task force to assess risk of asteroid collision how i found myself at last on the critical list the timing of their lives dear doctor irish court halts ira man s extradition to northern ireland burundi peace initiative fades after rebels reject mandela as mediator pe points the way forward to the ecb campaigners keep up pressure on nazi war crimes suspect jane ratcliffe yet more things you wouldn t know without the movies millennium bug fails to bite'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(str(x) for x in data.iloc[1,0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01242a",
   "metadata": {
    "papermill": {
     "duration": 0.00626,
     "end_time": "2023-05-26T23:44:01.299930",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.293670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code snippet ' '.join(str(x) for x in data.iloc[1,0:25]) performs a concatenation of the values in the second row (index 1) of the data DataFrame, specifically columns 0 to 24 (excluding column 25). The data.iloc[1, 0:25] expression selects the second row (index 1) of the data DataFrame and the columns 0 to 24 (excluding column 25). This creates a pandas Series object containing the values from the selected cells.\n",
    "\n",
    "The code then uses a generator expression (str(x) for x in data.iloc[1, 0:25]) to convert each value in the Series to a string.\n",
    "\n",
    "Finally, ' '.join(...) is used to join the string representation of each value with a space in between. The resulting string is the concatenation of all the values in the selected row and columns, separated by a space.\n",
    "\n",
    "This operation can be useful if you want to concatenate the text values from multiple columns into a single string, which can be further processed or analyzed as a unified text entity.\n",
    "\n",
    "If you run the provided code snippet, it will return the concatenated string of the values from the second row and columns 0 to 24 in the data DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649ca406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:01.314461Z",
     "iopub.status.busy": "2023-05-26T23:44:01.313942Z",
     "iopub.status.idle": "2023-05-26T23:44:01.842163Z",
     "shell.execute_reply": "2023-05-26T23:44:01.840792Z"
    },
    "papermill": {
     "duration": 0.538309,
     "end_time": "2023-05-26T23:44:01.844531",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.306222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "headlines = []\n",
    "for row in range(0,len(data.index)):\n",
    "    headlines.append(' '.join(str(x) for x in data.iloc[row,0:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831a650",
   "metadata": {
    "papermill": {
     "duration": 0.006348,
     "end_time": "2023-05-26T23:44:01.857976",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.851628",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code snippet  is iterating over each row of the data DataFrame and concatenating the values from columns 0 to 24 (excluding column 25) of each row into a single string. The resulting strings are then appended to a list called headlines.In this loop, row iterates over the range of row indices from 0 to the length of the index of the data DataFrame.\n",
    "\n",
    "For each iteration, ' '.join(str(x) for x in data.iloc[row, 0:25]) concatenates the values in columns 0 to 24 (excluding column 25) of the current row into a single string. This is achieved by using a generator expression (str(x) for x in data.iloc[row, 0:25]) to convert each value to a string and then joining them with a space in between using ' '.join(...).\n",
    "\n",
    "The resulting string is then appended to the headlines list using the .append() method.\n",
    "\n",
    "After the loop finishes, the headlines list will contain the concatenated strings of values from columns 0 to 24 for each row in the data DataFrame. This can be useful if you want to store or further process the concatenated headlines for later analysis or modeling tasks.\n",
    "\n",
    "Note that the resulting headlines list will have the same length as the number of rows in the data DataFrame, and each element in the list represents the concatenated headline for the corresponding row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd559ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:01.872667Z",
     "iopub.status.busy": "2023-05-26T23:44:01.872282Z",
     "iopub.status.idle": "2023-05-26T23:44:01.878840Z",
     "shell.execute_reply": "2023-05-26T23:44:01.877905Z"
    },
    "papermill": {
     "duration": 0.016302,
     "end_time": "2023-05-26T23:44:01.880737",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.864435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a  hindrance to operations   extracts from the leaked reports scorecard hughes  instant hit buoys blues jack gets his skates on at ice cold alex chaos as maracana builds up for united depleted leicester prevail as elliott spoils everton s party hungry spurs sense rich pickings gunners so wide of an easy target derby raise a glass to strupar s debut double southgate strikes  leeds pay the penalty hammers hand robson a youthful lesson saints party like it s      wear wolves have turned into lambs stump mike catches testy gough s taunt langer escapes to hit     flintoff injury piles on woe for england hunters threaten jospin with new battle of the somme kohl s successor drawn into scandal the difference between men and women sara denver  nurse turned solicitor diana s landmine crusade put tories in a panic yeltsin s resignation caught opposition flat footed russian roulette sold out recovering a title'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04efc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:01.895590Z",
     "iopub.status.busy": "2023-05-26T23:44:01.895185Z",
     "iopub.status.idle": "2023-05-26T23:44:03.394187Z",
     "shell.execute_reply": "2023-05-26T23:44:03.393139Z"
    },
    "papermill": {
     "duration": 1.509207,
     "end_time": "2023-05-26T23:44:03.396564",
     "exception": false,
     "start_time": "2023-05-26T23:44:01.887357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd3a00",
   "metadata": {
    "papermill": {
     "duration": 0.006798,
     "end_time": "2023-05-26T23:44:03.410731",
     "exception": false,
     "start_time": "2023-05-26T23:44:03.403933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code snippet y imports two modules from the sklearn library: CountVectorizer and RandomForestClassifier.CountVectorizer is a class in the sklearn.feature_extraction.text module. It is used for converting a collection of text documents into a matrix of token counts. It preprocesses the text data by tokenizing it into individual words or n-grams, and then counts the occurrences of these tokens in each document. This matrix representation can be used as input for various machine learning algorithms.\n",
    "\n",
    "By importing CountVectorizer, you gain access to the functionality provided by this class, such as fitting a vectorizer on a corpus of text data, transforming text into a numerical representation, and extracting vocabulary information. It is commonly used for text classification, sentiment analysis, and other natural language processing tasks.RandomForestClassifier is a class in the sklearn.ensemble module. It is an implementation of the random forest algorithm for classification tasks. Random forests are an ensemble learning method that combines multiple decision tree classifiers and aggregates their predictions to make a final classification decision.\n",
    "\n",
    "By importing RandomForestClassifier, you can create an instance of this class and utilize its methods for training a random forest classifier on labeled data, making predictions on new data, and evaluating the model's performance. Random forests are known for their ability to handle complex relationships in the data, handle missing values, and reduce overfitting.\n",
    "\n",
    "Once these modules are imported, you can use the functionality provided by CountVectorizer and RandomForestClassifier to preprocess text data and train a random forest classifier on that data, respectively.\n",
    "\n",
    "Please note that the code snippet you provided only imports these modules, and further code is required to utilize them effectively for specific tasks, such as preparing the data, splitting it into training and testing sets, fitting the classifier, making predictions, and evaluating the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ef313",
   "metadata": {
    "papermill": {
     "duration": 0.00666,
     "end_time": "2023-05-26T23:44:03.424409",
     "exception": false,
     "start_time": "2023-05-26T23:44:03.417749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CountVectorizer is like a special tool that can help us understand and work with words in a bunch of texts. Imagine we have a lot of books or stories. CountVectorizer helps us convert those stories into a special chart that shows us how many times each word appears in each story.\n",
    "\n",
    "First, CountVectorizer looks at all the words in the stories and counts how many times each word appears. Then, it creates a chart where each row represents a story, and each column represents a word. The numbers in the chart show how many times each word appears in each story.\n",
    "\n",
    "This chart can be really helpful for machines to understand and analyze the stories. For example, we can use this chart to teach a machine how to recognize if a story is happy or sad based on the words used. Or we can use it to see which words are most important in the stories.\n",
    "\n",
    "By importing CountVectorizer, we can use this special tool in our programs and tell the machine to do all these cool things with words! It helps us with things like understanding what the stories are about, figuring out people's feelings in the stories, and many other interesting things we can do with words.\n",
    "\n",
    "CountVectorizer is like a friend that helps us understand words and stories better, so we can do fun and smart things with them!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c197f",
   "metadata": {
    "papermill": {
     "duration": 0.006735,
     "end_time": "2023-05-26T23:44:03.437883",
     "exception": false,
     "start_time": "2023-05-26T23:44:03.431148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "RandomForestClassifier is like a special helper that can make decisions by looking at a lot of examples. Imagine we have a bunch of pictures of animals, and we want the computer to learn how to tell which animal is in each picture. RandomForestClassifier can help us with that!\n",
    "\n",
    "First, RandomForestClassifier gathers a group of special friends called decision trees. Each decision tree is like a smart friend that can make decisions based on certain features of the pictures. They look at things like the color, shape, and size of the animals in the pictures.\n",
    "\n",
    "Then, all the decision trees work together and share their opinions about which animal they think is in each picture. RandomForestClassifier listens to all the trees and combines their opinions to make a final decision about the animal in the picture.\n",
    "\n",
    "This can be really helpful because each decision tree has its own way of looking at the pictures. By listening to all the trees, RandomForestClassifier can make more accurate decisions and understand the pictures better.\n",
    "\n",
    "By importing RandomForestClassifier, we can use this special helper in our computer programs. We can show it lots of examples of animals and tell it which animal is in each picture. Then, RandomForestClassifier can learn from those examples and help us figure out which animal is in new pictures that it hasn't seen before.\n",
    "\n",
    "RandomForestClassifier is like a group of friends that work together to help the computer understand and recognize different animals in pictures. It's like having a team of smart friends who know a lot about animals and can make good guesses about which animal is in each picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a2dfb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:03.453112Z",
     "iopub.status.busy": "2023-05-26T23:44:03.452552Z",
     "iopub.status.idle": "2023-05-26T23:44:06.604048Z",
     "shell.execute_reply": "2023-05-26T23:44:06.603083Z"
    },
    "papermill": {
     "duration": 3.161742,
     "end_time": "2023-05-26T23:44:06.606318",
     "exception": false,
     "start_time": "2023-05-26T23:44:03.444576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## implement BAG OF WORDS\n",
    "countvector=CountVectorizer(ngram_range=(2,2))\n",
    "traindataset=countvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6b8df",
   "metadata": {
    "papermill": {
     "duration": 0.006582,
     "end_time": "2023-05-26T23:44:06.620412",
     "exception": false,
     "start_time": "2023-05-26T23:44:06.613830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "his code implements the Bag-of-Words model using the CountVectorizer class from the scikit-learn library. Let's break it down step by step:\n",
    "\n",
    "countvector = CountVectorizer(ngram_range=(2,2)): This line initializes an instance of the CountVectorizer class. The ngram_range=(2,2) parameter specifies that we want to consider only 2-word combinations, also known as bigrams. This means that the text will be tokenized into pairs of consecutive words.\n",
    "\n",
    "traindataset = countvector.fit_transform(headlines): This line applies the CountVectorizer to a dataset of headlines, represented by the headlines variable. The fit_transform() method of the CountVectorizer class performs two operations:\n",
    "\n",
    "fit(): This method learns the vocabulary from the headlines. It analyzes the text data and builds a dictionary of unique words (or bigrams in this case) called the vocabulary.\n",
    "transform(): This method converts the headlines into a matrix representation, where each row corresponds to a headline and each column represents the count of a specific word or bigram in that headline.\n",
    "The result, traindataset, is a sparse matrix that represents the bag-of-words representation of the headlines. Each row in the matrix corresponds to a headline, and each column represents a unique bigram from the vocabulary. The values in the matrix indicate the frequency of occurrence of each bigram in the respective headline.\n",
    "\n",
    "To summarize, this code applies the Bag-of-Words model to a dataset of headlines using the CountVectorizer class. It tokenizes the text into bigrams and creates a matrix representation where each row represents a headline, each column represents a bigram, and the values indicate the frequency of each bigram in the respective headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349febba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:44:06.634743Z",
     "iopub.status.busy": "2023-05-26T23:44:06.634377Z",
     "iopub.status.idle": "2023-05-26T23:45:07.773716Z",
     "shell.execute_reply": "2023-05-26T23:45:07.772876Z"
    },
    "papermill": {
     "duration": 61.155704,
     "end_time": "2023-05-26T23:45:07.782636",
     "exception": false,
     "start_time": "2023-05-26T23:44:06.626932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement RandomForest Classifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
    "randomclassifier.fit(traindataset,train['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e7b14",
   "metadata": {
    "papermill": {
     "duration": 0.006687,
     "end_time": "2023-05-26T23:45:07.797687",
     "exception": false,
     "start_time": "2023-05-26T23:45:07.791000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this code, we're using a special tool called \"CountVectorizer\" to help us count and understand words in some headlines. Imagine we have a list of headlines like \"I love ice cream\" or \"The sun is shining.\" We want to see how many times certain pairs of words appear in these headlines.\n",
    "\n",
    "First, we create a special box called \"countvector.\" It's like a magic box that can help us count words in the headlines. We tell the box that we want to look at pairs of words, like \"I love\" or \"the sun.\"\n",
    "\n",
    "Then, we take our list of headlines and put them inside the magic box. The box starts counting how many times each pair of words appears in each headline. It's like having a little helper who counts for us!\n",
    "\n",
    "After counting, the box gives us a special chart. In this chart, each row represents a headline, and each column represents a pair of words. The numbers in the chart show us how many times each pair of words appeared in each headline.\n",
    "\n",
    "This chart is really helpful because we can use it to learn more about the headlines. We can see which pairs of words are used a lot and which are used less often. It helps us understand how the words are connected in the headlines.\n",
    "\n",
    "So, by using CountVectorizer, we can count and understand the pairs of words in the headlines. It's like having a special box that helps us learn more about the words and how they are used together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e74c5",
   "metadata": {
    "papermill": {
     "duration": 0.006498,
     "end_time": "2023-05-26T23:45:07.811018",
     "exception": false,
     "start_time": "2023-05-26T23:45:07.804520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we create an instance of the CountVectorizer class and assign it to the variable countvector. The CountVectorizer class helps us convert text data into a numerical representation that we can use for analysis or machine learning.\n",
    "\n",
    "We set the parameter ngram_range to (2, 2), which means we want to consider pairs of words (bigrams) as features. This means that instead of looking at individual words, we look at two words together as a pair. For example, if we have a sentence like \"I love ice cream,\" the bigrams would be \"I love\" and \"love ice\" and \"ice cream.\"In this line, we use the fit_transform() method of the CountVectorizer instance (countvector) to convert our list of headlines (stored in the variable headlines) into a matrix of token counts.\n",
    "\n",
    "The fit_transform() method does two things. First, it \"fits\" the CountVectorizer to our data, which means it learns the vocabulary of all the unique words and bigrams present in the headlines. Then, it \"transforms\" the headlines into a numerical matrix representation.\n",
    "\n",
    "The resulting traindataset is a matrix where each row corresponds to a headline, and each column represents a unique word or bigram. The values in the matrix indicate the number of times each word or bigram appears in each headline. This matrix can be used as input for machine learning models or other analysis tasks.\n",
    "\n",
    "So, in summary, this code helps us convert a list of headlines into a matrix of word and bigram counts, which can be used for further analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4bd142b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:45:07.826382Z",
     "iopub.status.busy": "2023-05-26T23:45:07.826102Z",
     "iopub.status.idle": "2023-05-26T23:45:08.304441Z",
     "shell.execute_reply": "2023-05-26T23:45:08.303814Z"
    },
    "papermill": {
     "duration": 0.488486,
     "end_time": "2023-05-26T23:45:08.306400",
     "exception": false,
     "start_time": "2023-05-26T23:45:07.817914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Predict for the Test Dataset\n",
    "test_transform= []\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "test_dataset = countvector.transform(test_transform)\n",
    "predictions = randomclassifier.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b4d45",
   "metadata": {
    "papermill": {
     "duration": 0.006533,
     "end_time": "2023-05-26T23:45:08.320101",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.313568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code snippet you provided is used to predict the labels for the test dataset using a trained model. Let's break it down:In this block of code, we are preparing the test dataset for prediction. We create an empty list called test_transform to store the transformed version of each test example.\n",
    "\n",
    "For each row in the test dataset, we iterate through the range of indices from 0 to the length of the test dataset. Then, we use the iloc method to select the columns from index 2 to 26 (columns 2 to 26) in that row of the test dataset.\n",
    "\n",
    "Next, we convert the selected values to strings and join them together using a space as a separator. This creates a string representation of the features in that particular test example. Finally, we append the transformed string to the test_transform list.Here, we use the transform() method of the countvector object (which is an instance of CountVectorizer) to transform the test_transform data into a matrix representation similar to the one obtained during training. This ensures that the test data is represented in the same way as the training data.Finally, we use the predict() method of the randomclassifier object to make predictions on the transformed test dataset (test_dataset). The predict() method applies the trained model to the test dataset and returns the predicted labels for each example.\n",
    "\n",
    "The resulting predictions variable holds the predicted labels for the test dataset based on the trained model. These predictions can be further analyzed or compared with the actual labels to evaluate the model's performance.\n",
    "\n",
    "In summary, this code takes the test dataset, transforms it using the same CountVectorizer object used during training, and then makes predictions using a trained classifier (randomclassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f71897a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:45:08.335231Z",
     "iopub.status.busy": "2023-05-26T23:45:08.334383Z",
     "iopub.status.idle": "2023-05-26T23:45:08.338289Z",
     "shell.execute_reply": "2023-05-26T23:45:08.337406Z"
    },
    "papermill": {
     "duration": 0.013303,
     "end_time": "2023-05-26T23:45:08.340174",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.326871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import library to check accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d702f3d",
   "metadata": {
    "papermill": {
     "duration": 0.007045,
     "end_time": "2023-05-26T23:45:08.354552",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.347507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code  imports three modules from the sklearn.metrics library: classification_report, confusion_matrix, and accuracy_score. Let's discuss each of them:classification_report: This module provides a summary report of the main classification metrics. It computes various metrics such as precision, recall, F1-score, and support for each class in a classification problem. It is useful for evaluating the performance of a classification model and understanding the model's accuracy, precision, and recall for each class.\n",
    "\n",
    "confusion_matrix: This module allows us to create a confusion matrix, which is a table that shows the performance of a classification model by summarizing the counts of true positive, true negative, false positive, and false negative predictions. It helps in visualizing the model's performance and understanding how well it is predicting each class.\n",
    "\n",
    "accuracy_score: This module provides a function to calculate the accuracy score, which is a commonly used metric to evaluate the performance of a classification model. The accuracy score calculates the proportion of correctly predicted labels to the total number of samples. It gives us a single value that represents the overall accuracy of the model.\n",
    "\n",
    "By importing these modules, you gain access to the functionality provided by each module. You can use classification_report to generate a summary report of classification metrics, confusion_matrix to create a confusion matrix, and accuracy_score to calculate the accuracy score.\n",
    "\n",
    "These modules are commonly used for evaluating the performance of classification models and understanding how well the model is predicting the correct labels.\n",
    "\n",
    "Please note that the code snippet you provided only imports these modules, and further code is required to utilize them effectively, such as providing the actual and predicted labels as inputs to calculate the classification metrics, confusion matrix, and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6132fa7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T23:45:08.372184Z",
     "iopub.status.busy": "2023-05-26T23:45:08.371559Z",
     "iopub.status.idle": "2023-05-26T23:45:08.387959Z",
     "shell.execute_reply": "2023-05-26T23:45:08.387005Z"
    },
    "papermill": {
     "duration": 0.027905,
     "end_time": "2023-05-26T23:45:08.389806",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.361901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  45]\n",
      " [ 13 179]]\n",
      "0.8465608465608465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       186\n",
      "           1       0.80      0.93      0.86       192\n",
      "\n",
      "    accuracy                           0.85       378\n",
      "   macro avg       0.86      0.85      0.84       378\n",
      "weighted avg       0.86      0.85      0.85       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(test['Label'],predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(test['Label'],predictions)\n",
    "print(score)\n",
    "report=classification_report(test['Label'],predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef523d4",
   "metadata": {
    "papermill": {
     "duration": 0.00749,
     "end_time": "2023-05-26T23:45:08.405084",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.397594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code imported modules to evaluate the performance of the predicted labels (predictions) compared to the actual labels (test['Label']). Here, we use the confusion_matrix() function to calculate the confusion matrix. The confusion matrix gives us a table that shows the counts of true positives, true negatives, false positives, and false negatives. It helps us understand how well the model's predictions match the actual labels. The test['Label'] contains the actual labels, and predictions contains the predicted labels. The resulting matrix is stored in the matrix variable, and it is printed to the console using print(matrix).Next, we use the accuracy_score() function to calculate the accuracy score. The accuracy score measures the proportion of correctly predicted labels to the total number of samples. It gives us a single value that represents the overall accuracy of the model. The test['Label'] contains the actual labels, and predictions contains the predicted labels. The resulting accuracy score is stored in the score variable, and it is printed to the console using print(score).Finally, we use the classification_report() function to generate a report of classification metrics. This report includes metrics such as precision, recall, F1-score, and support for each class in the classification problem. It provides a summary of how well the model performed for each class. The test['Label'] contains the actual labels, and predictions contains the predicted labels. The resulting report is stored in the report variable, and it is printed to the console using print(report).\n",
    "\n",
    "In summary, this code evaluates the performance of the predicted labels by comparing them to the actual labels using the confusion matrix, accuracy score, and classification report. It helps us understand how well the model is performing and provides insights into its precision, recall, F1-score, and overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f92985",
   "metadata": {
    "papermill": {
     "duration": 0.007581,
     "end_time": "2023-05-26T23:45:08.420307",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.412726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the confusion matrix. It is a table that shows the performance of a classification model by summarizing the counts of true positives (top-left), true negatives (bottom-right), false positives (top-right), and false negatives (bottom-left). In this case, the matrix indicates that there are 139 true positives (correctly predicted positive labels), 47 false positives (incorrectly predicted positive labels), 13 false negatives (incorrectly predicted negative labels), and 179 true negatives (correctly predicted negative labels).This is the accuracy score. The accuracy score measures the proportion of correctly predicted labels to the total number of samples. In this case, the accuracy score is approximately 0.8413, which means that the model correctly predicted about 84.13% of the labels in the test dataset.This is the classification report. It provides various metrics such as precision, recall, and F1-score for each class (0 and 1). Precision represents the ability of the model to correctly identify positive samples, while recall represents the ability to find all positive samples. F1-score is a combination of precision and recall, providing a balanced measure of the model's performance. The \"support\" column indicates the number of samples for each class.\n",
    "\n",
    "In this case, for class 0, the precision is 0.91 (91%), which means that out of all the predicted positive labels, 91% were actually positive. The recall is 0.75 (75%), indicating that the model correctly identified 75% of the positive samples. The F1-score is 0.82 (82%), which is a balanced measure of precision and recall. There are 186 samples in class 0.\n",
    "\n",
    "For class 1, the precision is 0.79 (79%), meaning that out of all the predicted negative labels, 79% were actually negative. The recall is 0.93 (93%), indicating that the model correctly identified 93% of the negative samples. The F1-score is 0.86 (86%), providing a balanced measure. There are 192 samples in class 1.\n",
    "\n",
    "Overall, the classification report gives a summary of the model's performance for each class, indicating its precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49604f22",
   "metadata": {
    "papermill": {
     "duration": 0.007539,
     "end_time": "2023-05-26T23:45:08.435517",
     "exception": false,
     "start_time": "2023-05-26T23:45:08.427978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Accuracy: Accuracy measures the proportion of correctly predicted labels to the total number of samples. It provides an overall measure of the model's performance. However, accuracy alone may not be reliable when dealing with imbalanced datasets, where the number of samples in each class differs significantly.\n",
    "\n",
    "Precision: Precision is the proportion of correctly predicted positive labels out of all predicted positive labels. It represents the model's ability to correctly identify positive samples. A high precision indicates that the model has a low rate of false positives.\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate): Recall is the proportion of correctly predicted positive labels out of all actual positive labels. It measures the model's ability to find all positive samples. A high recall indicates that the model has a low rate of false negatives.\n",
    "\n",
    "F1-score: The F1-score is a combination of precision and recall, providing a balanced measure of the model's performance. It is the harmonic mean of precision and recall. F1-score considers both false positives and false negatives and is useful when the dataset is imbalanced."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 77.102,
   "end_time": "2023-05-26T23:45:09.363962",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-26T23:43:52.261962",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
